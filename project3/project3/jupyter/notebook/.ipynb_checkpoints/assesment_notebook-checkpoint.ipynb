{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "spark = SparkSession.builder. \\\n",
    "    appName(\"pyspark-1\"). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/dataset/nyc-jobs.csv\", header=True)\n",
    "# df.printSchema()\n",
    "# df.show()\n",
    "# get_salary_frequency(df)\n",
    "positionCategory:DataFrame=get_number_jobs_category(df)\n",
    "positionCategory.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salary_frequency(df: DataFrame) -> list:\n",
    "    row_list = df.select('Salary Frequency').distinct().collect()\n",
    "    return [row['Salary Frequency'] for row in row_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = [('A', 'Annual'), ('B', 'Daily')]\n",
    "expected_result = ['Annual', 'Daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_salary_frequency(mock_data: list, \n",
    "                              expected_result: list,\n",
    "                              schema: list = ['id', 'Salary Frequency']):  \n",
    "    mock_df = spark.createDataFrame(data = mock_data, schema = schema)\n",
    "    assert get_salary_frequency(mock_df) == expected_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation ---->  -0.2190694079975065\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/dataset/nyc-jobs.csv\", header=True)\n",
    "# df.printSchema()\n",
    "# df.show()\n",
    "# get_salary_frequency(df)\n",
    "# positionCategory:DataFrame=get_number_jobs_category(df)\n",
    "# positionCategory.show(truncate=False)\n",
    "# highestPaidSkill = highest_paid_skill(df)\n",
    "# highestPaidSkill.show()\n",
    "# higestAgencySalary:DataFrame = highest_salary_per_agency(df)\n",
    "# higestAgencySalary.show()\n",
    "# avgAgencySalary:DataFrame = avg_salary_per_agency(df)\n",
    "# avgAgencySalary.show() \n",
    "# print(avgAgencySalary.count())\n",
    "# print(df.count())\n",
    "# print(\"correlation ----> \",find_correlation(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whats the number of jobs posting per category (Top 10)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_jobs_category(df:DataFrame)->DataFrame:\n",
    "    res = df.groupBy(\"Job Category\").agg(sum(col(\"# Of Positions\")).alias(\"Number Of Position\"))\n",
    "    topTenRes = res.orderBy(col(\"Number Of Position\").desc()).limit(10)\n",
    "    return topTenRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = [('Health', '358.0'), ('Public Safety, Inspections, & Enforcement', '1407.0'), ('Maintenance & Operations', '212.0'), ('Policy, Research & Analysis', '312.0')]\n",
    "expected_result = [('Health', '358.0'), ('Public Safety, Inspections, & Enforcement', '1407.0'), ('Maintenance & Operations', '212.0'), ('Policy, Research & Analysis', '312.0')]\n",
    "test_get_number_jobs_category(mock_data,expected_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_number_jobs_category(mock_data: list, \n",
    "                              expected_result: list,\n",
    "                              schema: list = ['Job Category', '# Of Positions']):  \n",
    "    mock_df = spark.createDataFrame(data = mock_data, schema = schema)\n",
    "    expected_df = spark.createDataFrame(data = expected_result, schema = schema)\n",
    "    assert get_number_jobs_category(mock_df).subtract(expected_df).count() == 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the highest paid skills in the US market?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_paid_skill(df:DataFrame)-> DataFrame:\n",
    "    skillRes = df.groupBy(\"Preferred Skills\").agg(max(col(\"Salary Range To\")).alias(\"Max Salary\"))\n",
    "    higestPaid = skillRes.orderBy(col(\"Max Salary\").desc())\n",
    "    return higestPaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = [('journalism', '96000'), ('accredited by regional', '97873'), ('individuals must have', '99406'), ('including the 18 months of executive', '99394')]\n",
    "expected_result = [('journalism', '96000'), ('accredited by regional', '97873'), ('individuals must have', '99406'), ('including the 18 months of executive', '99394')]\n",
    "test_highest_paid_skill(mock_data,expected_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_highest_paid_skill(mock_data: list, \n",
    "                              expected_result: list,\n",
    "                              schema: list = ['Preferred Skills', 'Salary Range To']):  \n",
    "    mock_df = spark.createDataFrame(data = mock_data, schema = schema)\n",
    "    expected_df = spark.createDataFrame(data = expected_result, schema = schema)\n",
    "    assert highest_paid_skill(mock_df).subtract(expected_df).count() == 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Whats the job posting having the highest salary per agency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_salary_per_agency(df:DataFrame)->DataFrame:\n",
    "    agencyRes = df.groupBy(\"Posting Type\",\"Agency\").agg(max(col(\"Salary Range To\")).alias(\"Max Salary\"))\n",
    "    higestAgencyRes = agencyRes.orderBy(col(\"Max Salary\").desc())\n",
    "    return higestAgencyRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = [('Internal','LAW DEPARTMENT', '96000'), ('Internal','POLICE DEPARTMENT', '97873'), ('External','LAW DEPARTMENT', '97000'), ('External','POLICE DEPARTMENT', '99873')]\n",
    "expected_result = [('Internal','LAW DEPARTMENT', '96000'), ('Internal','POLICE DEPARTMENT', '97873'), ('External','LAW DEPARTMENT', '97000'), ('External','POLICE DEPARTMENT', '99873')]\n",
    "test_highest_salary_per_agency(mock_data,expected_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_highest_salary_per_agency(mock_data: list, \n",
    "                              expected_result: list,\n",
    "                              schema: list = ['Posting Type','Agency', 'Salary Range To']):  \n",
    "    mock_df = spark.createDataFrame(data = mock_data, schema = schema)\n",
    "    expected_df = spark.createDataFrame(data = expected_result, schema = schema)\n",
    "    assert highest_salary_per_agency(mock_df).subtract(expected_df).count() == 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whats the job positings average salary per agency for the last 2 years? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_salary_per_agency(df:DataFrame)->DataFrame:\n",
    "    lastYearDate=(datetime.now() + relativedelta(years=-2)).strftime(\"%Y-%m-%d\")+\"T00:00:00\"\n",
    "    agencyRes = df.filter(col(\"`Posting Date`\") >= lastYearDate)\n",
    "    avgAgencyRes = agencyRes.groupBy(\"Posting Type\",\"Agency\").agg(avg(col(\"Salary Range To\")).alias(\"Avg Salary\"))\n",
    "    return avgAgencyRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = [('Internal','LAW DEPARTMENT', '96000','2023-04-01T00:00:00'), ('Internal','POLICE DEPARTMENT', '97873','2022-04-01T00:00:00'), ('External','LAW DEPARTMENT', '97000','2023-04-05T00:00:00'), ('External','POLICE DEPARTMENT', '99873','2022-04-31T00:00:00')]\n",
    "expected_result = [('Internal','LAW DEPARTMENT', '96000.0','2023-04-01T00:00:00'), ('Internal','POLICE DEPARTMENT', '97873.0','2022-04-01T00:00:00'), ('External','LAW DEPARTMENT', '97000.0','2023-04-05T00:00:00'), ('External','POLICE DEPARTMENT', '99873.0','2022-04-31T00:00:00')]\n",
    "test_avg_salary_per_agency(mock_data,expected_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_avg_salary_per_agency(mock_data: list, \n",
    "                              expected_result: list,\n",
    "                              schema: list = ['Posting Type','Agency', 'Salary Range To','Posting Date']):  \n",
    "    mock_df = spark.createDataFrame(data = mock_data, schema = schema)\n",
    "    expected_df = spark.createDataFrame(data = expected_result, schema = schema).drop('Posting Date')\n",
    "    assert avg_salary_per_agency(mock_df).subtract(expected_df).count() == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there any correlation between the higher degree and the salary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correlation(df:DataFrame)->float:\n",
    "    testDf = df.withColumn(\"salary\",col(\"Salary Range To\").cast('int'))\n",
    "    testDf=testDf.withColumn(\"categ_num\", row_number().over(Window.orderBy(\"Minimum Qual Requirements\")))\n",
    "    corrRes = testDf.stat.corr(\"categ_num\",\"salary\")\n",
    "    return corrRes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = [('BE', '85000'), ('MCA', '94000'), ('Data Sience', '98000'), ('MS', '90000')]\n",
    "expected_result = 1\n",
    "test_find_correlation(mock_data,expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_find_correlation(mock_data: list, \n",
    "                              expected_result: list,\n",
    "                              schema: list = ['Minimum Qual Requirements', 'Salary Range To']):  \n",
    "    mock_df = spark.createDataFrame(data = mock_data, schema = schema)\n",
    "    assert find_correlation(mock_df) < expected_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
